{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "Huffman Coding is an algorithm used for lossless data compression. In this article we would describe and implement the algorithm. Finally, we will present a demonstration of its compression rate and how it compares to other compression algorithms.\n",
    "\n",
    "#### Keywords\n",
    "Huffman Coding, Huffman tree, lossless compression, entropy\n",
    "\n",
    "# Introduction\n",
    "The Huffman Coding is a lossless data compression algorithm, developed by David Huffman in the early of 50s while he was a PhD student at MIT. The algorithm is based on a binary-tree frequency-sorting method that allow encode any message sequence into shorter encoded messages and a method to reassemble into the original message without losing any data.\n",
    "\n",
    "### Lossless vs Lossy compression\n",
    "Lossless and lossy file compression describe whether all original data can be recovered when the file is uncompressed.\n",
    "\n",
    "With lossless compression, every bit of data originally in a file remains after it is uncompressed, and all the information is restored. Lossy compression reduces a file by permanently eliminating certain information, especially redundant information.\n",
    "\n",
    "When the file is uncompressed, some of the original information is not there, although the user may not notice it.\n",
    "\n",
    "### Entropy\n",
    "In information theory, Entropy is a measure of the \"disorder\"/randomness in a system. The entropy of a set of data is related to the amount of information that it contains which is directly related to the amount of compression that can be achieved. For example the more unique and randomly positioned letters we have in a sample text, the less compression we can achieve.\n",
    "\n",
    "* `TTTTTTTTT` can be compressed to `T9`\n",
    "* `ABCDEFGHI` string has the same length (9 characters), but higher entropy. Thus, lower possible compression rate.\n",
    "\n",
    "Entropy is the measure of redundancy or randomness of data, including strings. Highly random data will have an even distribution of tokens and will contain few meaningful patterns and high entropy. English text is redundant because the appearance of a 'q' generally precedes 'u'. 't' following 's' is a good guess too. \n",
    "\n",
    "Basically entropy rate establishes the statistical limits to possible data compression for random data.\n",
    "For example, the entropy rate of the English language is often cited as 1.5 bits per character (give or take). Typical encodings use 8 bits per character. So a maximally compressed text should be 1.5/8 (~19%) the size of the original\n",
    "\n",
    "### Heap\n",
    "A heap is a special type of tree-like structure that follows a specific rule. It as a collection of values arranged in a particular way. For example, in a \"max\" heap, every parent value is greater than or equal to its children. In a \"min\" heap, itâ€™s the opposite.\n",
    "\n",
    "![Heap structure](img/huffman/heap.png)\n",
    "\n",
    "This arrangement allows us to easily find the highest or lowest value in the heap, which is located at the top.\n",
    "\n",
    "In Huffman algorithm heap is being used for ordering letters based on their frequency in the text.\n",
    "\n",
    "### Huffman trees\n",
    "Huffman trees are binary trees (every node has only 2 children). Huffman tree basically sort the characters found in a text by their frequency. The more often a character occurs in the text, the higher it will be placed in the tree. However, all characters are leaf nodes. The interim nodes don't hold a character, but they hold the sum of the leafs below them.\n",
    "\n",
    "![Huffman tree](img/huffman/huffman_tree.png)\n",
    "\n",
    "Once we build the tree (based on char frequencies) we convert the data, piece-by-piece, into a binary code using the binary tree. In result, the higher frequency a character has, the shorter bit representation it gets. Latter serves best the compression interests.\n",
    "\n",
    "##### Decoding a binary code into text\n",
    "We need the hoffman tree (as a map) to decode the binary file. So, using that same binary tree we can simply start building up blocks of bits, until we find a code match (a character leaf node). There is no risk of conflict (e.g. two codes starting with the same sequence of bits), since all the characters are leaf nodes with unique bit representation *(look at the two examples in the figure above)*.\n",
    "\n",
    "# Implementation\n",
    "A simple Python implementation is provided below. Both compression (encoding) and decompression (decoding) is implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import TextIOWrapper\n",
    "import os\n",
    "import heapq\n",
    "    \n",
    "class HeapNode:\n",
    "    def __init__(self, char, freq):\n",
    "        self.char = char\n",
    "        self.freq = freq\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.freq < other.freq\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if other == None:\n",
    "            return False\n",
    "        if not isinstance(other, HeapNode):\n",
    "            return False\n",
    "        return self.freq == other.freq\n",
    "\n",
    "class Huffman:\n",
    "\n",
    "    input_file_path: str = \"\"\n",
    "    frequency: dict[str, int] = {}\n",
    "    heap: list[HeapNode] = []\n",
    "    codes: dict[str, str] = {}\n",
    "\n",
    "    def __init__(self, input_file_path: str):\n",
    "        self.input_file_path = input_file_path\n",
    "\n",
    "    def __calculate_frequencies(self, text: str):\n",
    "        '''Count the frequency of each character in the text and return the generated frequency dictionary.'''\n",
    "        self.frequency = {}\n",
    "        for char in text:\n",
    "            if not char in self.frequency:\n",
    "                self.frequency[char] = 0\n",
    "            self.frequency[char] += 1\n",
    "        return self.frequency\n",
    "\n",
    "    def __build_heap(self):\n",
    "        '''Build a heap from the frequency dictionary where the priority is the frequency of the character.'''\n",
    "        # Create a heap node for each character in the frequency dictionary. Go from the smallest frequency to the largest.\n",
    "        for char in self.frequency:\n",
    "            node = HeapNode(char, self.frequency[char])\n",
    "            heapq.heappush(self.heap, node)\n",
    "\n",
    "    def __merge_heap_nodes(self):\n",
    "        '''Build a huffman tree and save its root node in the heap.'''\n",
    "        # While there is more than one node in the heap, merge the two nodes with the smallest frequencies.\n",
    "        while len(self.heap) > 1:\n",
    "            node1 = heapq.heappop(self.heap) # Pop the node with the smallest frequency.\n",
    "            node2 = heapq.heappop(self.heap) # Pop the node with the second smallest frequency.\n",
    "\n",
    "            # Merged nodes are not characters, so we set the character to None.\n",
    "            merged = HeapNode(None, node1.freq + node2.freq)\n",
    "            merged.left = node1 # Left node is the smaller frequency node.\n",
    "            merged.right = node2 # Right node is the larger frequency node.\n",
    "\n",
    "            # Push the merged node back into the heap.\n",
    "            heapq.heappush(self.heap, merged)\n",
    "\n",
    "    def __traverse_tree_and_assign_codes(self):\n",
    "        '''Assign codes to characters in the tree.'''\n",
    "        root_node = heapq.heappop(self.heap) # Pop the root node from the heap.\n",
    "\n",
    "        # Traverse the tree and assign codes to characters.\n",
    "        code = \"\"\n",
    "        self.__visit_nodes_and_assign_codes_recursively(root_node, code)\n",
    "\n",
    "    def __visit_nodes_and_assign_codes_recursively(self, node: HeapNode, code: str):\n",
    "        '''Assign codes to characters in the tree.'''\n",
    "        if node is None:\n",
    "            return\n",
    "\n",
    "        # If the node is a character, assign the code to the character.\n",
    "        if node.char is not None:\n",
    "            self.codes[node.char] = code\n",
    "\n",
    "        # Traverse the left sub-node and assign a 0 to its code.\n",
    "        self.__visit_nodes_and_assign_codes_recursively(node.left, code + \"0\")\n",
    "        # Traverse the right sub-node and assign a 1 to its code.\n",
    "        self.__visit_nodes_and_assign_codes_recursively(node.right, code + \"1\")\n",
    "\n",
    "    def __get_encoded_text(self, text: str) -> str:\n",
    "        '''Replace characters with their corresponding codes.'''\n",
    "        encoded_text = \"\"\n",
    "        for char in text:\n",
    "            encoded_text += self.codes[char]\n",
    "        return encoded_text\n",
    "\n",
    "    def __pad_encoded_text(self, encoded_text: str) -> str:\n",
    "        '''Add padding (zeros) at the end of the encoded text to make it a multiple of 8.'''\n",
    "        # Calculate the number of padding bits needed to make the encoded text a multiple of 8.\n",
    "        extra_padding = 8 - len(encoded_text) % 8\n",
    "\n",
    "        # Add padding bits to the end of the encoded text.\n",
    "        for _ in range(extra_padding):\n",
    "            encoded_text += \"0\"\n",
    "\n",
    "        # Add the number of padding bits to the start of the encoded text.\n",
    "        padded_info = \"{0:08b}\".format(extra_padding)\n",
    "        padded_encoded_text = padded_info + encoded_text\n",
    "        return padded_encoded_text\n",
    "\n",
    "    def __save_output_file(self, padded_encoded_text: str, output_file: TextIOWrapper):\n",
    "        data_bytes = self.__convert_to_bytes(padded_encoded_text)\n",
    "        output_file.write(bytes(data_bytes))\n",
    "\n",
    "    def __convert_to_bytes(self, padded_encoded_text: str) -> list:\n",
    "        '''Convert the padded encoded text to a list of bytes.'''\n",
    "        if len(padded_encoded_text) % 8 != 0:\n",
    "            print(\"Encoded text not padded properly\")\n",
    "            exit(0)\n",
    "\n",
    "        data_bytes = bytearray()\n",
    "        for i in range(0, len(padded_encoded_text), 8):\n",
    "            byte = padded_encoded_text[i:i+8] # Get the next 8 bits.\n",
    "            data_bytes.append(int(byte, 2)) # Convert the 8 bits to an integer.\n",
    "        return data_bytes\n",
    "    \n",
    "    def __remove_padding(self, padded_encoded_text: str) -> str:\n",
    "        '''Remove padding (zeros) from the end of the encoded text.'''\n",
    "        padded_info = padded_encoded_text[:8] # Get the number of padding bits.\n",
    "        extra_padding = int(padded_info, 2) # Convert the number of padding bits to an integer.\n",
    "        padded_encoded_text = padded_encoded_text[8:] # Remove the number of padding bits from the encoded text.\n",
    "        encoded_text = padded_encoded_text[:-extra_padding] # Remove the padding bits from the end of the encoded text.\n",
    "        return encoded_text\n",
    "    \n",
    "    def __decode_text(self, encoded_text: str) -> str:\n",
    "        '''Decode the encoded text.'''\n",
    "        current_code = \"\"\n",
    "        decoded_text = \"\"\n",
    "        for bit in encoded_text:\n",
    "            current_code += bit\n",
    "            if current_code in self.codes.values(): # If the current code is in the codes dictionary, add the character to the decoded text.\n",
    "                key_index = list(self.codes.values()).index(current_code) # Get the key of the current code.\n",
    "                decoded_text += list(self.codes.keys())[key_index] # Add the character to the decoded text.\n",
    "                current_code = \"\" # Reset the current code.\n",
    "        return decoded_text\n",
    "\n",
    "    def compress(self):\n",
    "        file_name, file_extension = os.path.splitext(self.input_file_path)\n",
    "        output_file_path = file_name + \".bin\"\n",
    "\n",
    "        with open(self.input_file_path, 'r') as input_file, open(output_file_path, 'wb') as output_file:\n",
    "            text = input_file.read()\n",
    "            text = text.rstrip()\n",
    "\n",
    "            self.__calculate_frequencies(text)\n",
    "            self.__build_heap()\n",
    "            self.__merge_heap_nodes()\n",
    "            self.__traverse_tree_and_assign_codes()\n",
    "            encoded_text = self.__get_encoded_text(text)\n",
    "            padded_encoded_text = self.__pad_encoded_text(encoded_text)\n",
    "\n",
    "            self.__save_output_file(padded_encoded_text, output_file)\n",
    "\n",
    "        # Print the size of the original file and the size of the compressed file.\n",
    "        print(\"The file was compressed successfully.\")\n",
    "        print(f\"\\tOriginal file size: {os.path.getsize(self.input_file_path)} bytes\")\n",
    "        print(f\"\\tCompressed file size: {os.path.getsize(output_file_path)} bytes\")\n",
    "        return output_file_path\n",
    "        \n",
    "    def decompress(self, input_file_path: str):\n",
    "        file_name, file_extension = os.path.splitext(input_file_path)\n",
    "        output_file_path = file_name + \"_decompressed.txt\"\n",
    "\n",
    "        with open(input_file_path, 'rb') as input_file, open(output_file_path, 'w') as output_file:\n",
    "            bit_string = \"\"\n",
    "\n",
    "            byte = input_file.read(1)\n",
    "            while byte and len(byte) > 0:\n",
    "                byte = ord(byte) # Convert the byte to an integer.\n",
    "                bits = bin(byte)[2:].rjust(8, '0') # Convert the integer to a binary string.\n",
    "                bit_string += bits # Add the binary string to the bit string.\n",
    "                byte = input_file.read(1) # Read the next byte.\n",
    "            \n",
    "            encoded_text = self.__remove_padding(bit_string)\n",
    "            decoded_text = self.__decode_text(encoded_text)\n",
    "            output_file.write(decoded_text)\n",
    "\n",
    "        # Print the size of the original file and the size of the decompressed file.\n",
    "        print(\"The file was decompressed successfully.\")\n",
    "        print(f\"\\tOriginal file size: {os.path.getsize(input_file_path)} bytes\")\n",
    "        print(f\"\\tDecompressed file size: {os.path.getsize(output_file_path)} bytes\")\n",
    "        return output_file_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo\n",
    "\n",
    "In this demo we compress a small `.txt` file (size = ~5KB). The output file's size is 2.5KB (50% compression rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file was compressed successfully.\n",
      "\tOriginal file size: 4877 bytes\n",
      "\tCompressed file size: 2653 bytes\n",
      "The file was decompressed successfully.\n",
      "\tOriginal file size: 2653 bytes\n",
      "\tDecompressed file size: 4876 bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data/huffman/20_great_books_decompressed.txt'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demo\n",
    "huffman = Huffman(\"data/huffman/20_great_books.txt\")\n",
    "huffman.compress()\n",
    "huffman.decompress(\"data/huffman/20_great_books.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation\n",
    "\n",
    "### Compression Efficiency\n",
    "In real life Huffman algorithm results into 50-80% compression ratio. Which is not bad for a lossless compressiong algorithm, discovered 75 years ago. That's why Huffman trees are still being widely used nowadays.\n",
    "\n",
    "### Other algorithms\n",
    "There are other popular compression algorithms - like `LZ77` and `LZW`. Latter algorithms however are more appropriate for repetitive data, while Huffman encoding is used for non-repetitive data.\n",
    "\n",
    "For example, take the string `123123123`.\n",
    "\n",
    "LZW will identify that `123` is repeated three times and essentially create a dictionary of codes for sequences. It will esentially say when I say `A` I mean `123` here is `AAA` (or 24 bits).\n",
    "\n",
    "Huffman will detect the frequency of bytes (let's assume the text above is ASCII, which will make `ABC` all single byte code points), so `A=3`, `B=3`, `C=3` and there are no other items, so I can use 1.5 bits (well a 1 and 2 bit combo) to represent all characters. So let's say `A=0`, `B=10`, `C=11`. Huffman will encode the text `ABCABCABC` as (in bits) `010110101101011` (or 15 bits).\n",
    "\n",
    "### Combination of encoders\n",
    "What if we used Huffman on the LZW result?\n",
    "Well `AAA` can be represented with a single bit (Let's choose `0`), so the output would be simply `000` (3 bits only).\n",
    "\n",
    "# Summary\n",
    "Huffman trees have been the de-facto standard for optimal encoding since their introduction. Therefore Huffman is widely used in all the mainstream compression formats that you might encounter - from GZIP, PKZIP and BZIP2, to image formats such as JPEG and PNG.\n",
    "\n",
    "Being familiar with this algorithm and its greedy approach for building prefix trees is a foundamental step in every computer scientist career."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
